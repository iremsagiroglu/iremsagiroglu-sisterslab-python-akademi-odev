{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# all_data Projesi\n",
    "\n",
    "1. Bütün text küçük harfe çevrilecek\n",
    "\n",
    "2. Türkçe karakterler replace edilecek\n",
    "\n",
    "ş -> s\n",
    "\n",
    "ı -> i\n",
    "\n",
    "ö -> o\n",
    "\n",
    "ğ -> g\n",
    "\n",
    "ç -> c\n",
    "\n",
    "ü -> u\n",
    "\n",
    "3. Noktalama işaretleri kaldırılacak \n",
    "\n",
    "4. Bir satır tamamen sayılardan oluşuyorsa satırı yeni dosyaya ekleme \n",
    "\n",
    "5. Her satırda bir cümle olacak şekilde satırları düzenleyin \n",
    "\n",
    "6. Duplicate veri barındırmayacak\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_data.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "import os\n",
    "\n",
    "with open(\"all_data.txt\", \"r+\") as f:\n",
    "    text = text.lower()\n",
    "    f.write(text)\n",
    "\n",
    "with open(\"all_data.txt\", \"r+\", encoding=\"ISO-8859-1\") as f, open(\"tempdata.txt\", \"w\", encoding=\"ISO-8859-1\") as g:\n",
    "\n",
    "    for line in f:\n",
    "        line = sent_tokenize(line)\n",
    "        for sentence in line:\n",
    "            g.write(sentence + \"\\n\")\n",
    "\n",
    "os.replace('tempdata.txt','all_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def remove_punctuation(data_text):\n",
    "    data_text = data_text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return data_text\n",
    "\n",
    "def remove_turkish_characters(data_text):\n",
    "    d ={\"ç\":\"c\", \"ğ\":\"g\", \"ı\":\"i\", \"ö\":\"o\", \"ş\":\"s\", \"ü\":\"u\"}\n",
    "    for key, value in d.items():\n",
    "        data_text = data_text.replace(key, value)\n",
    "\n",
    "    data_text = remove_punctuation(data_text)\n",
    "    return data_text\n",
    "    \n",
    "text = remove_turkish_characters(text)\n",
    "\n",
    "with open(\"all_data.txt\", \"w\") as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "with open('all_data.txt') as infile, open('tempdata.txt', 'w') as outfile:\n",
    "  for line in infile:\n",
    "    if not any(i.isdigit() for i in line) and line.strip():\n",
    "      outfile.write(line)\n",
    "\n",
    "os.replace('tempdata.txt','all_data.txt')\n",
    "\n",
    "\n",
    "with open('all_data.txt', 'r') as f:\n",
    "    unique_lines = set(f.readlines())\n",
    "with open('all_data.txt', 'w') as f:\n",
    "    f.writelines(unique_lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
